{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2a: CNNs (LFW Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version :\t 2.0.1+cu118\n",
      "CUDA Available? :\t True\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch, torchvision\n",
    "\n",
    "print(\"PyTorch Version :\\t\", torch.__version__)\n",
    "print(\"CUDA Available? :\\t\", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "# Cached in \"~/scikit_learn_data\" after first download\n",
    "lfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.4)\n",
    "\n",
    "X = lfw_people.images\n",
    "y = lfw_people.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into a training set and a test set using a stratified k fold\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, \n",
    "    random_state=42)\n",
    "\n",
    "# Normalise and reshape data into 4D array (added dimension is channels)\n",
    "X_train = X_train[:, np.newaxis, :, :] / 255\n",
    "X_test = X_test[:, np.newaxis, :] / 255\n",
    "\n",
    "# Load all data and labels into Tensor objects\n",
    "X_train = torch.tensor(X_train, device=\"cuda\")\n",
    "y_train = torch.tensor(y_train, device=\"cuda\")\n",
    "X_test = torch.tensor(X_test, device=\"cuda\")\n",
    "y_test = torch.tensor(y_test, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LFWCNN(nn.Module):\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.num_classes = num_classes\n",
    "        self.sequential = self._make_conv(self.in_channels)\n",
    "        self.classifier = self._make_clsf(self.num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "    def _make_conv(self, in_channels):\n",
    "        layers = [\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "        ]\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_clsf(self, out_channels):\n",
    "        layers = [\n",
    "            nn.Linear(64 * 50 * 37, 256),\n",
    "            nn.Linear(256, out_channels)\n",
    "        ]\n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model No. of Parameters: 30331463\n",
      "LFWCNN(\n",
      "  (sequential): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=118400, out_features=256, bias=True)\n",
      "    (1): Linear(in_features=256, out_features=7, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the model\n",
    "model = LFWCNN(1, num_classes=len(np.unique(y)))\n",
    "model.to(\"cuda\")\n",
    "\n",
    "# Model info\n",
    "print(\"Model No. of Parameters:\", \n",
    "    sum([param.nelement() for param in model.parameters()]))\n",
    "print(model)\n",
    "\n",
    "# Loss function and optimizer + hyperparameters\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20]\tLoss: 22.76771\n",
      "Epoch [2/20]\tLoss: 3.71115\n",
      "Epoch [3/20]\tLoss: 0.00000\n",
      "Epoch [4/20]\tLoss: 0.00000\n",
      "Epoch [5/20]\tLoss: 0.00000\n",
      "Epoch [6/20]\tLoss: 0.00000\n",
      "Epoch [7/20]\tLoss: 0.00000\n",
      "Epoch [8/20]\tLoss: 0.00000\n",
      "Epoch [9/20]\tLoss: 0.00000\n",
      "Epoch [10/20]\tLoss: 0.00000\n",
      "Epoch [11/20]\tLoss: 0.00000\n",
      "Epoch [12/20]\tLoss: 0.00000\n",
      "Epoch [13/20]\tLoss: 0.00000\n",
      "Epoch [14/20]\tLoss: 0.00000\n",
      "Epoch [15/20]\tLoss: 0.00000\n",
      "Epoch [16/20]\tLoss: 0.00000\n",
      "Epoch [17/20]\tLoss: 0.00000\n",
      "Epoch [18/20]\tLoss: 0.00000\n",
      "Epoch [19/20]\tLoss: 0.00000\n",
      "Epoch [20/20]\tLoss: 0.00000\n",
      "Total training time: 29.29731297492981 s\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Split the training further into training and validation sets\n",
    "# X_train, X_val = X_train[:-64], X_train[-64:]\n",
    "# y_train, y_val = y_train[:-64], y_train[-64:]\n",
    "\n",
    "# Batch the training data\n",
    "X_train_batches = torch.split(X_train, BATCH_SIZE)\n",
    "y_train_batches = torch.split(y_train, BATCH_SIZE)\n",
    "\n",
    "# Set the model in training mode\n",
    "model.train()\n",
    "start = time.time()\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (images, labels) in enumerate(zip(X_train_batches, y_train_batches)):\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # # Evaluate using validation set\n",
    "    # with torch.no_grad():\n",
    "    #     outputs = model(X_val)\n",
    "    #     _, predicted = torch.max(outputs.data, 1)\n",
    "    #     total = y_val.size(0)\n",
    "    #     correct = (predicted == y_val).sum().item()\n",
    "    #     val_acc = (correct / total) * 100\n",
    "\n",
    "    # Training report\n",
    "    print(f\"Epoch [{epoch+1}/{NUM_EPOCHS}]\\tLoss: {loss.item():.5f}\", end=\"\")\n",
    "    # print(f\"\\tVal.: {val_acc:.2f}%\", end=\"\")\n",
    "    print()\n",
    "\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(f\"Total training time: {elapsed} s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 80.75% (in 0.173s)\n"
     ]
    }
   ],
   "source": [
    "# Split the test data into batches\n",
    "X_test_batches = torch.split(X_test, BATCH_SIZE)\n",
    "y_test_batches = torch.split(y_test, BATCH_SIZE)\n",
    "\n",
    "# Set the model in evaluation (test) mode\n",
    "model.eval()\n",
    "start = time.time()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in zip(X_test_batches, y_test_batches):\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print(f\"Test accuracy: {100 * correct / total:.2f}% (in {elapsed:.3f}s)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
